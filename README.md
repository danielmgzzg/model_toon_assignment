# Model Toon Project

## Description

This is a linear regression model to predict the probability of a person to purchase.

## Table of Contents

- [Installation and Usage Guide](#installation-and-usage-guide)
  - [Cloning the Repository](#cloning-the-repository)
  - [Setting Up the Environment](#setting-up-the-environment)
- [How to Use](#how-to-use)
- [Project Functionality](#project-functionality)
- [Makefile Commands](#makefile-commands)
- [Project Structure](#project-structure)

## Installation and Usage Guide

### Cloning the Repository

1. To clone this repository to your local machine, use the following command in your terminal:

```bash
git clone <repository-url>
```

Replace `<repository-url>` with the URL of this repository.

### Setting Up the Environment

1. To set up the virtual environment and install the necessary dependencies, execute the following command:

```bash
make environment
```

This command will create a virtual environment and install all the required packages listed in the `requirements.txt` file.

## How to Use

2. To perform unit testing, use the following command:

```bash
make test
```

3. If you wish to remove the created virtual environment, you can do so by running:

```bash
make clean
```

This command will delete the virtual environment and all its associated files.

## Important Notes

### Azure Account Requirement

To pull data from Azure Blob Storage, a valid Azure account is necessary. You can log in to your Azure account using the following command:

```bash
az login
```

### Data Set File

The `data_set.db` file is not included in the repository. It is generated by the `data_preparation.py` script using the `data_set.csv` file. The `data_set.csv` file is retrieved from Azure Blob Storage using Data Version Control (DVC). If you wish to create a `data_set.db` file, you can use the `example_data_set.csv` file which is included in the repository.

### Fetching Different Versions of DVC Tracked Files

If you need to fetch a different version of DVC tracked files, you can use the following command:

```bash
dvc checkout <tag> -- <file_name>
```

In the above command, replace `<tag>` with the tag of the version you want to fetch and replace `<file_name>` with the name of the file you want to fetch. This command will retrieve the specified version of the DVC tracked files.

To fetch the latest version of the DVC tracked files, you can use the following command:

```bash
dvc pull <file_name>
```

Please replace `<file_name>` with the name of the file you want to fetch. This command will pull the latest version of the specified DVC tracked file.

## Project Functionality

This project encompasses a comprehensive machine learning pipeline, offering a range of functionalities from data preprocessing to model evaluation. Here’s a detailed breakdown:

- **DVC Extraction with Azure Blob Storage**: The project utilizes Data Version Control (DVC) to manage and version the machine learning models. This is integrated with Azure Blob Storage, providing a robust and scalable solution for storing and versioning models.

## Makefile Commands

1. **`init`**: This command initializes the project. It sets up a virtual environment and installs all the necessary packages listed in the `requirements.txt` file.

2. **`install`**: This command is used to install the required packages for the project. It reads the `requirements.txt` file and installs all the listed packages.

3. **`data`**: This command pulls the data required for the project. It uses Data Version Control (DVC) to fetch the data from the current `.dvc` files.

4. **`environment`**: This command sets up the project environment. It creates a virtual environment and installs all the necessary packages.

5. **`run`**: This command executes the main script of the project. It's the primary command used to run the project.

6. **`test`**: This command runs the unit tests for the project. It's used to verify that all parts of the project are working correctly.

7. **`clean`**: This command cleans up the project by deleting the virtual environment and all its associated files. It's useful for resetting the project environment.

## Project Structure

> Note it also includes the s

```toml
├── Makefile # Makefile commands
├── README.md # this file
├── notebooks # Jupyter notebooks
│   └── example_usage.ipynb # exercise notebook
├── requirements.txt # project dependencies
├── scripts # shell scripts
│   ├── environment.sh # environment setup script
│   └── setup_project.sh # project setup script
├── setup.py # setup file
├── src # source code
│   ├── pipelines # pipeline files
│   │   ├── compile_pipeline.py
│   │   ├── deploy_pipeline.py
│   │   ├── model_toon_pipeline.py
│   │   ├── model_toon_pipeline.yaml
│   ├── data # data files
│   │   ├── column_info.csv
│   │   ├── column_info.csv.dvc
│   │   ├── data_set.csv
│   │   ├── data_set.csv.dvc
│   │   ├── data_set.db
│   │   ├── marketing_list.csv
│   │   └── plots
│   ├── data_preparation.py # data preprocessing script
│   ├── evaluation.py # evaluation script
│   ├── inference.py # inference script
│   ├── main.py # main script
│   ├── model.py # logistic regression model
│   ├── models # trained models
│   │   ├── logistic_regression_model.pkl # trained logistic regression model fetched from Azure Blob Storage
│   │   └── logistic_regression_model.pkl.dvc # DVC file for logistic regression model
│   ├── training.py
│   └── utils # utility functions
│       ├── check_azure_credentials.py
│       ├── run_command.py
│       └── sqlite_handler.py
├── tests # unit tests
│   ├── test_check_azure_credentials.py
│   ├── test_data_preparation.py
│   ├── test_evaluation.py
│   ├── test_inference.py
│   ├── test_model.py
│   ├── test_run_command.py
│   └── test_sqlite_hanlder.py
└── venv # virtual environment
```
